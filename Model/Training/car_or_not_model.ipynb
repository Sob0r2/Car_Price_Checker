{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set device to cuda\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Download pre-trained model\n",
    "model = models.vgg16_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of paths to the image with appropriate labels.\n",
    "def get_img_paths_with_labels(data_dir, label):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            image_paths.append(file_path)\n",
    "            labels.append(label)\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading images and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list of str): List of file paths to the images.\n",
    "        labels (list of int): List of labels corresponding to the images.\n",
    "        transform (callable, optional): Optional transform to be applied to each image.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\") # Open image as RGB\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the folders with data\n",
    "data_dir = {\n",
    "    \"train_1\": os.path.join(os.getenv(\"CAR_OR_NOT\"), \"Car_photos_train\"),\n",
    "    \"train_0\": os.path.join(os.getenv(\"CAR_OR_NOT\"), \"Not_car_photos_train\"),\n",
    "    \"test_1\":  os.path.join(os.getenv(\"CAR_OR_NOT\"), \"Car_photos_test\"),\n",
    "    \"test_0\":  os.path.join(os.getenv(\"CAR_OR_NOT\"), \"Not_car_photos_test\"),\n",
    "}\n",
    "\n",
    "# Load images from directories\n",
    "train_car_paths, train_car_labels = get_img_paths_with_labels(\n",
    "    data_dir[\"train_1\"], 1\n",
    ")\n",
    "train_not_car_paths, train_not_car_labels = get_img_paths_with_labels(\n",
    "    data_dir[\"train_0\"], 0\n",
    ")\n",
    "\n",
    "test_car_paths, test_car_labels = get_img_paths_with_labels(\n",
    "    data_dir[\"test_1\"], 1\n",
    ")\n",
    "test_not_car_paths, test_not_car_labels = get_img_paths_with_labels(\n",
    "    data_dir[\"test_0\"], 0\n",
    ")\n",
    "\n",
    "# Combine the paths and labels\n",
    "train_image_paths = train_car_paths + train_not_car_paths\n",
    "train_labels = train_car_labels + train_not_car_labels\n",
    "\n",
    "test_image_paths = test_car_paths + test_not_car_paths\n",
    "test_labels = test_car_labels + test_not_car_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.4297, 0.4375, 0.4382], device='cuda:0'), Std: tensor([0.2463, 0.2426, 0.2417], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def save_transformed_image(tensor_image, output_path):\n",
    "    \"\"\"\n",
    "    Save a tensor image as a .png file after transforming it to a PIL image.\n",
    "\n",
    "    Args:\n",
    "        tensor_image (Tensor): The image tensor to save.\n",
    "        output_path (str): The path where the image will be saved.\n",
    "    \"\"\"\n",
    "    # Convert the tensor image to a numpy array in the format (H, W, C)\n",
    "    np_image = tensor_image.permute(1, 2, 0).cpu().numpy()\n",
    "    # Rescale the image to the range [0, 255] and convert to uint8\n",
    "    np_image = (np_image * 255).astype(np.uint8)\n",
    "    # Convert to PIL image and save\n",
    "    pil_image = Image.fromarray(np_image)\n",
    "    pil_image.save(output_path)\n",
    "\n",
    "# Define transformation to convert images to tensors\n",
    "preprocess_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create training dataset with preprocessing transformations\n",
    "train_dataset_preprocess = CustomImageDataset(\n",
    "    train_image_paths, train_labels, transform=preprocess_transform\n",
    ")\n",
    "\n",
    "# Initialize DataLoader for the training dataset\n",
    "loader = DataLoader(\n",
    "    train_dataset_preprocess, batch_size=64, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "# Calculate mean and standard deviation for normalization\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "total_images = 0\n",
    "\n",
    "# Iterate over the data to compute mean and std for each channel\n",
    "for images, _ in loader:\n",
    "    images = images.to(device)\n",
    "    batch_samples = images.size(0)  # Number of images in the batch\n",
    "    images = images.view(batch_samples, images.size(1), -1)  # Flatten the images\n",
    "    mean += images.mean(dim=2).sum(dim=0)  # Sum over batch\n",
    "    std += images.std(dim=2).sum(dim=0)  # Sum over batch\n",
    "    total_images += batch_samples\n",
    "\n",
    "# Compute the final mean and std\n",
    "mean /= total_images\n",
    "std /= total_images\n",
    "\n",
    "print(f\"Mean: {mean}, Std: {std}\")\n",
    "\n",
    "# Define transformations for training and testing datasets\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),  # Resize images to 224x224\n",
    "    transforms.RandomRotation(degrees=45),  # Random rotation\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    transforms.RandomVerticalFlip(p=0.05),  # Random vertical flip with low probability\n",
    "    transforms.RandomGrayscale(p=0.33),  # Random grayscale with a 33% chance\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=mean, std=std),  # Normalize using computed mean and std\n",
    "])\n",
    "\n",
    "test_transformations = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=mean, std=std),  # Normalize using computed mean and std\n",
    "])\n",
    "\n",
    "# Create the training and testing datasets with transformations\n",
    "train_dataset = CustomImageDataset(\n",
    "    train_image_paths, train_labels, transform=train_transformations\n",
    ")\n",
    "test_dataset = CustomImageDataset(\n",
    "    test_image_paths, test_labels, transform=test_transformations\n",
    ")\n",
    "\n",
    "# Initialize DataLoader for training and testing datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False  # Freeze feature extraction layers\n",
    "\n",
    "# Add an output layer to have only to classes\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "# Move model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Add optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters())\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Train the model on the training dataset and validate it on the validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        criterion (nn.Module): The loss function.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer.\n",
    "        num_epochs (int): Number of epochs to train the model.\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Training loop with progress bar (tqdm)\n",
    "        with tqdm(\n",
    "            total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"\n",
    "        ) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()  # Zero the gradients before backpropagation\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Calculate the loss and accuracy for the current batch\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                # Update the progress bar with current batch results\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(\n",
    "                    {\"Loss\": loss.item(), \"Accuracy\": 100.0 * correct / total}\n",
    "                )\n",
    "\n",
    "        # Calculate and print training loss and accuracy after each epoch\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = 100.0 * correct / total\n",
    "        print(\n",
    "            f\"\\nEpoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # Validate the model after each epoch\n",
    "        validate_model(model, val_loader, criterion)\n",
    "\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    \"\"\"\n",
    "    Validate the model on the validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to validate.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        criterion (nn.Module): The loss function.\n",
    "    \"\"\"\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Validation loop with progress bar (tqdm)\n",
    "    with tqdm(total=len(val_loader), desc=\"Validation\", unit=\"batch\") as pbar:\n",
    "        with torch.no_grad(): # No gradient computation during validation\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                # Update the progress bar with current batch results\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(\n",
    "                    {\"Val Loss\": loss.item(), \"Val Accuracy\": 100.0 * correct / total}\n",
    "                )\n",
    "\n",
    "    # Calculate and print validation loss and accuracy after each epoch\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = 100.0 * correct / total\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 109/109 [00:28<00:00,  3.81batch/s, Loss=0.0242, Accuracy=90.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10], Loss: 0.3594, Accuracy: 90.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:20<00:00,  1.57batch/s, Val Loss=5.81e-7, Val Accuracy=98]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0817, Validation Accuracy: 98.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 109/109 [00:35<00:00,  3.09batch/s, Loss=0.00376, Accuracy=96]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10], Loss: 0.1344, Accuracy: 95.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:14<00:00,  2.24batch/s, Val Loss=1.56e-6, Val Accuracy=97.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1058, Validation Accuracy: 97.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 109/109 [00:40<00:00,  2.71batch/s, Loss=0.311, Accuracy=96.1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10], Loss: 0.1516, Accuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:14<00:00,  2.16batch/s, Val Loss=0, Val Accuracy=98.3]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0916, Validation Accuracy: 98.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 109/109 [00:42<00:00,  2.59batch/s, Loss=1.81, Accuracy=95.9]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10], Loss: 0.1996, Accuracy: 95.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:15<00:00,  2.12batch/s, Val Loss=3.4e-5, Val Accuracy=97.3]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1359, Validation Accuracy: 97.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 109/109 [00:48<00:00,  2.26batch/s, Loss=0.0175, Accuracy=95.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10], Loss: 0.1599, Accuracy: 95.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:15<00:00,  2.06batch/s, Val Loss=0, Val Accuracy=98.2]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0630, Validation Accuracy: 98.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 109/109 [00:49<00:00,  2.20batch/s, Loss=0.00138, Accuracy=96.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/10], Loss: 0.1775, Accuracy: 96.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:16<00:00,  1.98batch/s, Val Loss=0, Val Accuracy=97.8]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1622, Validation Accuracy: 97.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 109/109 [00:55<00:00,  1.97batch/s, Loss=0.00372, Accuracy=96.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/10], Loss: 0.1248, Accuracy: 96.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:17<00:00,  1.80batch/s, Val Loss=0, Val Accuracy=98.4]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0791, Validation Accuracy: 98.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 109/109 [01:12<00:00,  1.51batch/s, Loss=0.0015, Accuracy=97.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/10], Loss: 0.0840, Accuracy: 97.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:17<00:00,  1.83batch/s, Val Loss=0, Val Accuracy=98.1]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0745, Validation Accuracy: 98.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 109/109 [01:02<00:00,  1.73batch/s, Loss=0.00808, Accuracy=97.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/10], Loss: 0.0844, Accuracy: 97.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:17<00:00,  1.79batch/s, Val Loss=1.49e-8, Val Accuracy=98.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0676, Validation Accuracy: 98.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 109/109 [01:09<00:00,  1.58batch/s, Loss=0.203, Accuracy=97.2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/10], Loss: 0.1044, Accuracy: 97.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:17<00:00,  1.86batch/s, Val Loss=0, Val Accuracy=98.1]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0855, Validation Accuracy: 98.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, test_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    \"C:\\\\Users\\\\jakub\\\\PycharmProjects\\\\Car_Finder\\\\Model\\\\Weights\\\\car_or_not_model.pth\",\n",
    ")\n",
    "print(f\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
